{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-05T23:39:31.270517Z",
     "iopub.status.busy": "2025-05-05T23:39:31.270234Z",
     "iopub.status.idle": "2025-05-05T23:39:37.799033Z",
     "shell.execute_reply": "2025-05-05T23:39:37.797983Z",
     "shell.execute_reply.started": "2025-05-05T23:39:31.270493Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!pip install ultralytics albumentations==1.3.0 timm==0.9.2 -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-05T23:39:46.332889Z",
     "iopub.status.busy": "2025-05-05T23:39:46.332501Z",
     "iopub.status.idle": "2025-05-05T23:39:54.834784Z",
     "shell.execute_reply": "2025-05-05T23:39:54.834158Z",
     "shell.execute_reply.started": "2025-05-05T23:39:46.332857Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import os\n",
    "import timm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "import cv2\n",
    "from sklearn.model_selection import KFold\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from torch.amp import autocast, GradScaler\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "os.environ['NO_ALBUMENTATIONS_UPDATE'] = '1'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-05T23:39:58.133981Z",
     "iopub.status.busy": "2025-05-05T23:39:58.133490Z",
     "iopub.status.idle": "2025-05-05T23:39:58.144684Z",
     "shell.execute_reply": "2025-05-05T23:39:58.143883Z",
     "shell.execute_reply.started": "2025-05-05T23:39:58.133949Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "\n",
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)  # For multi-GPU setups\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "def seed_worker(worker_id):\n",
    "    worker_seed = SEED + worker_id\n",
    "    np.random.seed(worker_seed)\n",
    "    random.seed(worker_seed)\n",
    "    torch.manual_seed(worker_seed)\n",
    "    torch.cuda.manual_seed(worker_seed)\n",
    "\n",
    "seed_everything(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-05T23:54:24.874309Z",
     "iopub.status.busy": "2025-05-05T23:54:24.873963Z",
     "iopub.status.idle": "2025-05-05T23:54:24.894461Z",
     "shell.execute_reply": "2025-05-05T23:54:24.893661Z",
     "shell.execute_reply.started": "2025-05-05T23:54:24.874284Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('/kaggle/input/lacuna-solar-survey-challenge/Train.csv')\n",
    "test = pd.read_csv('/kaggle/input/lacuna-solar-survey-challenge/Test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-05T23:54:26.608443Z",
     "iopub.status.busy": "2025-05-05T23:54:26.608161Z",
     "iopub.status.idle": "2025-05-05T23:54:27.121328Z",
     "shell.execute_reply": "2025-05-05T23:54:27.120546Z",
     "shell.execute_reply.started": "2025-05-05T23:54:26.608424Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "pan_nbr_counts = data['pan_nbr'].value_counts().sort_index()  # or sort by frequency with `.sort_values()`\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.barplot(x=pan_nbr_counts.index, y=pan_nbr_counts.values, palette='viridis')\n",
    "plt.title('Distribution of pan_nbr Counts')\n",
    "plt.xlabel('pan_nbr')\n",
    "plt.ylabel('Count')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-05T23:54:43.086533Z",
     "iopub.status.busy": "2025-05-05T23:54:43.086215Z",
     "iopub.status.idle": "2025-05-05T23:54:43.597948Z",
     "shell.execute_reply": "2025-05-05T23:54:43.597080Z",
     "shell.execute_reply.started": "2025-05-05T23:54:43.086505Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import ast\n",
    "\n",
    "for idx,row in data.iterrows():\n",
    "    # Parse the polygon string into a list of tuples\n",
    "    try:\n",
    "        polygon = ast.literal_eval(row['polygon'])\n",
    "    except (SyntaxError, ValueError):\n",
    "        print(f\"Invalid polygon format at index {idx}\")\n",
    "        continue\n",
    "    invalid_found = False\n",
    "    for point in polygon:\n",
    "        x, y = point\n",
    "        # Check if x or y are strings containing letters\n",
    "        if isinstance(x, str) and any(c.isalpha() for c in x):\n",
    "            invalid_found = True\n",
    "            print(x)\n",
    "            break\n",
    "        if isinstance(y, str) and any(c.isalpha() for c in y):\n",
    "            invalid_found = True\n",
    "            print(y)\n",
    "            break\n",
    "    \n",
    "    if invalid_found:\n",
    "        print(f\"Row {idx} has invalid coordinates in its polygon\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-05T23:54:45.427012Z",
     "iopub.status.busy": "2025-05-05T23:54:45.426734Z",
     "iopub.status.idle": "2025-05-05T23:54:45.433831Z",
     "shell.execute_reply": "2025-05-05T23:54:45.432981Z",
     "shell.execute_reply.started": "2025-05-05T23:54:45.426991Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "data.iloc[5385, data.columns.get_loc('polygon')] = \"[(2250, 3318.0), (1639, 3334.0), (1707.2, 3334.0), (1642, 3233.0), (2248, 3221.0)]\"\n",
    "data = data.drop(index=4031)\n",
    "data = data.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-05T23:55:50.716199Z",
     "iopub.status.busy": "2025-05-05T23:55:50.715822Z",
     "iopub.status.idle": "2025-05-05T23:55:51.765085Z",
     "shell.execute_reply": "2025-05-05T23:55:51.764105Z",
     "shell.execute_reply.started": "2025-05-05T23:55:50.716168Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision.transforms as T\n",
    "import matplotlib.patches as patches\n",
    "import ast\n",
    "\n",
    "# Define transforms\n",
    "transforms = T.Compose([\n",
    "    T.ToTensor(),          # Convert OpenCV numpy array to tensor (C, H, W)\n",
    "    T.Resize((512, 512)),\n",
    "])\n",
    "\n",
    "# Load image and polygon data\n",
    "img_id = \"IDmfKSa\"  # Change this to test different IDs\n",
    "img_path = os.path.join(\"/kaggle/input/lacuna-solar-survey-challenge/images/\", img_id + '.jpg')\n",
    "\n",
    "# Load and convert image\n",
    "img = cv2.imread(img_path)\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "original_height, original_width = img.shape[:2]\n",
    "\n",
    "# Apply transforms\n",
    "transformed_img = transforms(img)  # Shape: (3, 512, 512)\n",
    "\n",
    "# Convert tensor to numpy (do this ONCE)\n",
    "def tensor_to_numpy(img_tensor):\n",
    "    img_np = img_tensor.numpy().transpose(1, 2, 0) * 255\n",
    "    return img_np.astype(np.uint8)\n",
    "\n",
    "# Create figure and plot base image ONCE\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.imshow(tensor_to_numpy(transformed_img))\n",
    "ax = plt.gca()\n",
    "\n",
    "# Extract all polygons for this image\n",
    "polygons = []\n",
    "for row in data[data[\"ID\"] == img_id]['polygon']:\n",
    "    polygons.append(ast.literal_eval(row))  # Handle multiple polygon entries\n",
    "# Calculate scaling factors\n",
    "scale_width = 512 / original_width\n",
    "scale_height = 512 / original_height\n",
    "# Process all polygons\n",
    "def polygon_to_box(poly):\n",
    "    x_coords = [x for (x, y) in poly]\n",
    "    y_coords = [y for (x, y) in poly]\n",
    "    return [min(x_coords), min(y_coords), max(x_coords), max(y_coords)]\n",
    "\n",
    "for original_polygon in polygons:\n",
    "    # Scale coordinates\n",
    "    scaled_polygon = [(x * scale_width, y * scale_height) for (x, y) in original_polygon]\n",
    "    # Convert to bounding box\n",
    "    scaled_bbox = polygon_to_box(scaled_polygon)\n",
    "    \n",
    "    # Create and add rectangle patch\n",
    "    rect = patches.Rectangle(\n",
    "        (scaled_bbox[0], scaled_bbox[1]),\n",
    "        scaled_bbox[2] - scaled_bbox[0],\n",
    "        scaled_bbox[3] - scaled_bbox[1],\n",
    "        linewidth=1, edgecolor='red', facecolor='none'\n",
    "    )\n",
    "    ax.add_patch(rect)  # Add to existing axes\n",
    "\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-05T23:56:31.368788Z",
     "iopub.status.busy": "2025-05-05T23:56:31.368492Z",
     "iopub.status.idle": "2025-05-05T23:56:31.376547Z",
     "shell.execute_reply": "2025-05-05T23:56:31.375555Z",
     "shell.execute_reply.started": "2025-05-05T23:56:31.368765Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class SolarPanelDataset(Dataset):\n",
    "    def __init__(self, dataframe, transform=None, to_train=True, cache_images=True):\n",
    "        self.dataframe = dataframe\n",
    "        self.transform = transform\n",
    "        self.to_train = to_train\n",
    "        self.placement_map = {\"roof\": 0, \"openspace\": 1, \"r_openspace\": 2, \"S-unknown\": 3}\n",
    "        \n",
    "        # Cache images during initialization and resize to 1280*720\n",
    "        self.images = {}\n",
    "        if cache_images:\n",
    "            print(\"Caching images...\")\n",
    "            for idx, row in tqdm(dataframe.iterrows(), total=len(dataframe)):\n",
    "                try:\n",
    "                    image = cv2.imread(row[\"path\"])\n",
    "                    if image is not None:\n",
    "                        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "                        self.images[row['ID']] = cv2.resize(image, (1280,720))\n",
    "                    else:\n",
    "                        print(f\"Warning: Unable to read image at {row['path']}\")\n",
    "                except Exception as e:\n",
    "                    print(f\"Error loading image at index {idx}: {e}\")\n",
    "            \n",
    "            print(f\"Successfully cached {len(self.images)} out of {len(dataframe)} images\")\n",
    "    def __len__(self):\n",
    "        return len(self.dataframe)\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.dataframe.iloc[idx]\n",
    "        \n",
    "        image = self.images[row['ID']]\n",
    "        # Improved metadata encoding\n",
    "        metadata = torch.zeros(5)\n",
    "        metadata[0] = 1.0 if row[\"img_origin\"] == \"D\" else 0.0\n",
    "        placement = self.placement_map.get(row[\"placement\"], 3)\n",
    "        metadata[1 + placement] = 1.0  # One-hot encoding\n",
    "        if self.transform:\n",
    "            image = self.transform(image=image)['image']\n",
    "        if self.to_train:\n",
    "            target = torch.tensor([row[\"boil_nbr\"], row[\"pan_nbr\"]], dtype=torch.float32)\n",
    "            return image, metadata, target\n",
    "        return image, metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-05T23:56:36.258688Z",
     "iopub.status.busy": "2025-05-05T23:56:36.258371Z",
     "iopub.status.idle": "2025-05-05T23:56:36.264883Z",
     "shell.execute_reply": "2025-05-05T23:56:36.264076Z",
     "shell.execute_reply.started": "2025-05-05T23:56:36.258661Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class EfficientNetV2Meta(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.backbone = timm.create_model(\"tf_efficientnetv2_b3\", pretrained=True, num_classes=0)  # Larger backbone\n",
    "        self.meta_processor = nn.Sequential(\n",
    "            nn.Linear(5, 128),\n",
    "            nn.LayerNorm(128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(128, 64)\n",
    "        )\n",
    "        self.attention = nn.MultiheadAttention(embed_dim=64, num_heads=4)\n",
    "        self.regressor = nn.Sequential(\n",
    "            nn.Linear(self.backbone.num_features + 64, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(512, 2),\n",
    "            nn.Softplus()  # Better for count predictions\n",
    "        )\n",
    "\n",
    "    def forward(self, image, metadata):\n",
    "        img_features = self.backbone(image)\n",
    "        meta_features = self.meta_processor(metadata.unsqueeze(0))\n",
    "        attn_output, _ = self.attention(meta_features, meta_features, meta_features)\n",
    "        combined = torch.cat([img_features, attn_output.squeeze(0)], dim=1)\n",
    "        return self.regressor(combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-05T23:56:42.164231Z",
     "iopub.status.busy": "2025-05-05T23:56:42.163905Z",
     "iopub.status.idle": "2025-05-05T23:56:42.169928Z",
     "shell.execute_reply": "2025-05-05T23:56:42.169128Z",
     "shell.execute_reply.started": "2025-05-05T23:56:42.164205Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Advanced Augmentation\n",
    "train_transform = A.Compose([\n",
    "    A.RandomResizedCrop(512, 512, scale=(0.7, 1.0)),\n",
    "    A.HorizontalFlip(p=0.5),\n",
    "    A.VerticalFlip(p=0.5),\n",
    "    A.RandomRotate90(p=0.5),\n",
    "    A.GaussianBlur(blur_limit=(3, 7), p=0.3),\n",
    "    A.CLAHE(clip_limit=4.0, p=0.5),\n",
    "    A.HueSaturationValue(p=0.3),\n",
    "    A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
    "    ToTensorV2()\n",
    "])\n",
    "\n",
    "test_transform = A.Compose([\n",
    "    A.Resize(512, 512),\n",
    "    A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
    "    ToTensorV2()\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-05T23:56:47.138419Z",
     "iopub.status.busy": "2025-05-05T23:56:47.138122Z",
     "iopub.status.idle": "2025-05-05T23:56:47.150129Z",
     "shell.execute_reply": "2025-05-05T23:56:47.149165Z",
     "shell.execute_reply.started": "2025-05-05T23:56:47.138396Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Training Configuration\n",
    "def train(fold=0, epochs=20, batch_size=16):\n",
    "    train_df = data\n",
    "    train_df = train_df.groupby(\"ID\").agg({\n",
    "        \"boil_nbr\": \"sum\",\n",
    "        \"pan_nbr\": \"sum\",\n",
    "        \"img_origin\": \"first\",\n",
    "        \"placement\": \"first\"\n",
    "    }).reset_index()\n",
    "    train_df[\"path\"] = \"/kaggle/input/lacuna-solar-survey-challenge/images/\" + train_df[\"ID\"] + \".jpg\"\n",
    "\n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    splits = list(kf.split(train_df))\n",
    "    train_idx, val_idx = splits[fold]\n",
    "\n",
    "    train_ds = SolarPanelDataset(train_df.iloc[train_idx], transform=train_transform)\n",
    "    val_ds = SolarPanelDataset(train_df.iloc[val_idx], transform=test_transform)\n",
    "\n",
    "    train_loader = DataLoader(train_ds, batch_size=batch_size, \n",
    "                             shuffle=True, num_workers=4, pin_memory=True,worker_init_fn=seed_worker)\n",
    "    val_loader = DataLoader(val_ds, batch_size=batch_size*2, \n",
    "                           shuffle=False, num_workers=4, pin_memory=True,worker_init_fn=seed_worker)\n",
    "\n",
    "    model = EfficientNetV2Meta().cuda()\n",
    "    criterion = nn.HuberLoss(delta=1.0)  # Improved loss function\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=1e-4, weight_decay=1e-4)\n",
    "    scheduler = optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0=10, T_mult=2)\n",
    "    scaler = GradScaler()\n",
    "\n",
    "    best_mae = float('inf')\n",
    "    for epoch in range(epochs):\n",
    "        # Training loop\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        pbar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{epochs} [Train]\")\n",
    "        for images, meta, targets in pbar:\n",
    "            images = images.cuda(non_blocking=True)\n",
    "            meta = meta.cuda(non_blocking=True)\n",
    "            targets = targets.cuda(non_blocking=True)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            with autocast(device_type='cuda'):\n",
    "                outputs = model(images, meta)\n",
    "                loss = criterion(outputs, targets)\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "            \n",
    "            train_loss += loss.item()\n",
    "            pbar.set_postfix(loss=loss.item())\n",
    "        \n",
    "        # Validation loop\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        preds, truths = [], []\n",
    "        with torch.no_grad():\n",
    "            for images, meta, targets in tqdm(val_loader, desc=f\"Epoch {epoch+1}/{epochs} [Val]\"):\n",
    "                images = images.cuda(non_blocking=True)\n",
    "                meta = meta.cuda(non_blocking=True)\n",
    "                targets = targets.cuda(non_blocking=True)\n",
    "                \n",
    "                with autocast(device_type='cuda'):\n",
    "                    outputs = model(images, meta)\n",
    "                    loss = criterion(outputs, targets)\n",
    "                \n",
    "                val_loss += loss.item()\n",
    "                preds.append(outputs.cpu().numpy())\n",
    "                truths.append(targets.cpu().numpy())\n",
    "        \n",
    "        # Metrics calculation\n",
    "        train_loss /= len(train_loader)\n",
    "        val_loss /= len(val_loader)\n",
    "        preds = np.concatenate(preds)\n",
    "        truths = np.concatenate(truths)\n",
    "        mae = mean_absolute_error(truths, preds)\n",
    "        \n",
    "        print(f\"Epoch {epoch+1}/{epochs}\")\n",
    "        print(f\"Train Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f} | Val MAE: {mae:.4f}\")\n",
    "        \n",
    "        # Model checkpointing based on MAE\n",
    "        if mae < best_mae:\n",
    "            best_mae = mae\n",
    "            torch.save(model.state_dict(), f\"best_model_fold{fold}.pth\")\n",
    "        \n",
    "        scheduler.step()\n",
    "    \n",
    "    return best_mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-23T04:09:14.778115Z",
     "iopub.status.busy": "2025-03-23T04:09:14.777822Z",
     "iopub.status.idle": "2025-03-23T04:09:14.796173Z",
     "shell.execute_reply": "2025-03-23T04:09:14.795398Z",
     "shell.execute_reply.started": "2025-03-23T04:09:14.778086Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Inference with TTA\n",
    "def predict(test_df, model_paths, batch_size=32):\n",
    "    test_df[\"path\"] = \"/kaggle/input/lacuna-solar-survey-challenge/images/\" + test_df[\"ID\"] + \".jpg\"\n",
    "    test_ds = SolarPanelDataset(test_df, transform=test_transform, to_train=False)\n",
    "    test_loader = DataLoader(test_ds, batch_size=batch_size, shuffle=False, num_workers=4, worker_init_fn=seed_worker)\n",
    "    \n",
    "    predictions = np.zeros((len(test_df), 2))\n",
    "    for path in model_paths:\n",
    "        model = EfficientNetV2Meta().cuda()\n",
    "        model.load_state_dict(torch.load(path, weights_only=True))  # Safer loading\n",
    "        model.eval()\n",
    "        \n",
    "        tta_preds = []\n",
    "        with torch.no_grad():\n",
    "            for images, meta in tqdm(test_loader, desc=\"Inference\"):\n",
    "                images = images.cuda()\n",
    "                meta = meta.cuda()\n",
    "                with autocast(device_type='cuda'):\n",
    "                    outputs = model(images, meta)\n",
    "                tta_preds.append(outputs.cpu().numpy())\n",
    "        \n",
    "        predictions += np.concatenate(tta_preds)\n",
    "    \n",
    "    return predictions / len(model_paths)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-05T23:56:52.645481Z",
     "iopub.status.busy": "2025-05-05T23:56:52.645175Z",
     "iopub.status.idle": "2025-05-05T23:57:04.448764Z",
     "shell.execute_reply": "2025-05-05T23:57:04.447611Z",
     "shell.execute_reply.started": "2025-05-05T23:56:52.645459Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# Main Execution\n",
    "if __name__ == \"__main__\":\n",
    "    # Train multiple folds\n",
    "    folds = 3\n",
    "    model_paths = []\n",
    "    for fold in range(folds):\n",
    "        print(f\"Training fold {fold+1}/{folds}\")\n",
    "        best_mae = train(fold=fold, epochs=52, batch_size=16)\n",
    "        model_paths.append(f\"best_model_fold{fold}.pth\")\n",
    "    \n",
    "    # Prepare submission\n",
    "    test_df = pd.read_csv(\"/kaggle/input/lacuna-solar-survey-challenge/Test.csv\")\n",
    "    predictions = predict(test_df, model_paths, batch_size=64)\n",
    "    \n",
    "    # Create submissions\n",
    "    submission = pd.DataFrame({\n",
    "        \"ID\": np.repeat(test_df[\"ID\"].values, 2),\n",
    "        \"Target\": predictions.flatten()\n",
    "    })\n",
    "    submission[\"ID\"] += np.where(\n",
    "        submission.groupby(\"ID\").cumcount() == 0,\n",
    "        \"_boil\",\n",
    "        \"_pan\"\n",
    "    )\n",
    "    submission.to_csv(\"submission_original2.csv\", index=False)\n",
    "    \n",
    "    int_submission = submission.copy()\n",
    "    int_submission[\"Target\"] = np.round(int_submission[\"Target\"]).astype(int)\n",
    "    int_submission.to_csv(\"submission_integer2.csv\", index=False)\n",
    "    \n",
    "    print(\"Submissions saved with shapes:\", submission.shape, int_submission.shape)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 6691299,
     "sourceId": 10783793,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30919,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0b074c585dd5460f892711429f1d78aa": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "3db63fd099ba4a2a8d3ffcaa147b6011": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8f26197afbe3469cb2d27ea32f7257ee",
      "max": 31471874,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_d026f74db1264804b09f4b93da7bf720",
      "value": 31471874
     }
    },
    "5a5479ef19af4814b4a227ea44ffd90a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e52204a5e84f419994c7017fc2b3bbf8",
      "placeholder": "​",
      "style": "IPY_MODEL_0b074c585dd5460f892711429f1d78aa",
      "value": " 31.5M/31.5M [00:00&lt;00:00, 56.8MB/s]"
     }
    },
    "5ca7b048742c49e986dd8e30727367a7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "60f4949511b44ae499946129cee86819": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "654c794449bd42378ad0ff1ba20a3842": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_77ac0e5761554e789f001c1045129ea8",
       "IPY_MODEL_3db63fd099ba4a2a8d3ffcaa147b6011",
       "IPY_MODEL_5a5479ef19af4814b4a227ea44ffd90a"
      ],
      "layout": "IPY_MODEL_60f4949511b44ae499946129cee86819"
     }
    },
    "69079a20dea64e91885053bf2cc54a4c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "77ac0e5761554e789f001c1045129ea8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_69079a20dea64e91885053bf2cc54a4c",
      "placeholder": "​",
      "style": "IPY_MODEL_5ca7b048742c49e986dd8e30727367a7",
      "value": "model.safetensors: 100%"
     }
    },
    "8f26197afbe3469cb2d27ea32f7257ee": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d026f74db1264804b09f4b93da7bf720": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "e52204a5e84f419994c7017fc2b3bbf8": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
